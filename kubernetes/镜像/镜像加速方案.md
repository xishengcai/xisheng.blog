镜像背景知识

为了理解overlaybd的原理，首先需要了解容器镜像的分层机制。容器镜像由多个增量layer文件组成，在使用时进行叠加，这样在镜像分发时只需要对layer文件进行分发。每一层实质上都是与上一层的差异（包括文件的添加，修改或删除）的压缩包。

容器引擎可以通过其storage driver，按照约定的方式将差异叠加起来，然后以Read-Only的模式挂载到指定目录，该目录即称为**lower_dir**；而以Read/Write模式挂载的可写层，挂载目录则一般称为**upper_dir**。



1.  **Stargz Snapshotter**

   实现原理

   	1. Stargz： 使用可索引的压缩技术，之前构建镜像是打包成一整个的tar文件，现在是 打包成多个可索引的 gzip 文件
   	2. Snapshotter： 延迟拉取数据， 只拉取部分元数据，然后启动镜像，剩下的部分先远程挂载，再慢慢下载。

   

   

2. **DADI**

   ​	overlaybd本身没有文件的概念，它只是将镜像抽象为虚拟块设备，并在其上装载常规的文件系统。当用户应用读取数据时，该读取请求首先由常规的文件系统处理，将请求转换为虚拟块设备的一次或多次读取。这些读取请求会被转发到用户态的接收程序，即overlaybd的运行时载体，最后转换为对一个或多个layer的随机读取。

   ​	

   ​	与传统镜像一样，overlaybd在内部仍然保留着layer分层的结构，但每层的内容都是文件系统变更差异对应的一系列data block。overlaybd向上提供了一个合并视图，对layer的叠加规则很简单，即对于任意一个data block，总是使用最后的变更，在layer中未发生变更的块均视为全零块；向下又提供了将一系列data block导出成一个layer文件的功能，该文件高密度非稀疏、且可索引。因此，对块设备某个连续LBA范围进行读操作，可能包含了原本属于多层的小块数据段，我们将这些小块数据段称为segment。从segment的属性中找到层号，便能够继续映射到对这层的layer文件的读取上来。传统的容器镜像可以将它的layer文件保存在Registry或者对象存储上，那么overlaybd镜像自然也可以

   ![image-20210507104820917](https://cai-hello-1253732611.cos.ap-shanghai.myqcloud.com/share/024823.png)

   为了更好的兼容性，overlaybd在layer文件的最外层，包装了一层tar文件的头和尾，这样伪装成一个tar文件。由于 tar内部仅一个文件，不影响按需读取。目前无论是docker、containerd或者buildkit，对镜像的下载或上传默认都有untar和tar的流程，不侵入代码是无法逾越的，所以增加tar伪装有利于兼容性和流程的统一，例如在镜像转换、构建、或者全量下载使用时，都无需修改代码，只需提供插件即可。

   

   

   架构

   <img src="https://cai-hello-1253732611.cos.ap-shanghai.myqcloud.com/share/024412.png" alt="image-20210507104407002" style="zoom:50%;" />

   

3. **Nydus**

   实现原理：

   ​	

   nydus 项目优化了现有的 OCI 镜像标准格式，并以此设计了一个用户态的文件系统。通过这些优化，nydus 能够提供这些特性：

   - 容器镜像按需下载，用户不再需要下载完整镜像就能启动容器
   - 块级别的镜像数据去重，最大限度为用户节省存储资源
   - 镜像只有最终可用的数据，不需要保存和下载过期数据
   - 端到端的数据一致性校验，为用户提供更好的数据保护
   - 兼容 OCI 分发标准和 artifacts 标准，开箱即可用
   - 支持不同的镜像存储后端，镜像数据不只可以存放在镜像仓库，还可以放到 NAS 或者类似 S3 的对象存储上
   - 与 Dragonfly 的良好集成

   

   架构上， nydus 主要包含一个新的镜像格式，和一个负责解析容器镜像的 FUSE 用户态文件系统进程。

   <img src="https://cai-hello-1253732611.cos.ap-shanghai.myqcloud.com/share/074821.png" alt="image-20210507154811432" style="zoom:50%;" />

ydus 能够解析 FUSE 或者 virtiofs 协议来支持传统的 runc 容器或者 Kata 容器。容器仓库，OSS 对象存储，NAS，以及 Dragonfly 的超级节点和 peer 节点都可以作为 nydus 的镜像数据源。同时， nydus 还可以配置一个本地缓存，从而避免每次启动都从远端数据源拉取数据。

镜像格式方面， nydus 把一个容器镜像分成元数据和数据两层。其中元数据层是一颗自校验的哈希树。每个文件和目录都是哈希树中的一个附带哈希值的节点。一个文件节点的哈希值是由文件的数据确定，一个目录节点的哈希值则是由该目录下所有文件和目录的哈希值确定。每个文件的数据被按照固定大小切片并保存到数据层中。数据切片可以在不同文件以及不同镜像中的不同文件共享。

![2.png](https://ucc.alicdn.com/pic/developer-ecology/fecb55c5e2a549f3ae9888eb3ec7f672.png)

# Nydus 能为用户带来什么？

用户如果部署了 nydus 镜像服务，最直观的一个感受就是，容器启动变快了，从以前的明显时间消耗，变成了几乎瞬间就能启动起来。在我们的测试中， nydus 能够把常见镜像的启动时间，从数分钟缩短到数秒钟。

![3.png](https://ucc.alicdn.com/pic/developer-ecology/fd1de3126c1046369f2b4937cc7cdad5.png)

另外一个不那么明显但也很重要的改进，是 nydus 能够为用户提供容器运行时数据一致性校验。在传统的镜像中，镜像数据会先被解压到本地文件系统，再由容器应用去访问使用。解压前，镜像数据是完整校验的。但是解压之后，镜像数据不再能够被校验。这带来的一个问题就是，如果解压后的镜像数据被无意或者恶意地修改，用户是无法感知的。而 nydus 镜像不会被解压到本地，同时可以对每一次数据访问进行校验，如果数据被篡改，则可以从远端数据源重新拉取。

![4.png](https://ucc.alicdn.com/pic/developer-ecology/7d1fd0e0bdcf4613a94f4977846c1dc4.png)





性能上的横向对比暂时还没有具体数据，对比 stargz 来说 nydus 在 rootfs mount 时只有一层，stargz 有多层，nydus 优势是性能有提升，有数据端到端的校验。对比 dadi 来说，nydus 是文件系统粒度的，好处是能对镜像做文件级的操作，比如做镜像扫描，统计安全分析，镜像修复等，dadi 是块设备粒度的。









